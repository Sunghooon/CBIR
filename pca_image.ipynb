{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f30a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thanks for Code from https://www.kaggle.com/mirzarahim/introduction-to-pca-image-compression-example\n",
    "# Introduction to PCA: Image Compression example\n",
    "\n",
    "# https://github.com/vivekrmk/Image-Compression-Principal-Component-Analysis-Pytorch/blob/main/Pytorch_PCA_journey.ipynb\n",
    "# https://github.com/Erikfather/PCA-python/blob/master/Face_Rec.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "309fdb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 2060\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Checking GPU Units\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c7ee4477",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../../../Documents/shopee-product-matching/'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import cv2, matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from matplotlib.image import imread\n",
    "from IPython.display import Image\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "train = pd.read_csv(DATA_PATH + 'train.csv')\n",
    "train['image'] = DATA_PATH + 'train_images/' + train['image']\n",
    "\n",
    "n_train = 12000\n",
    "n_test = 1000\n",
    "n_valid = 300\n",
    "K = 120 # PCA, num of principal components\n",
    "\n",
    "sample = train.head(n_train)\n",
    "test   = train.loc[n_train+1:n_train+n_test]\n",
    "test = test.reset_index(drop=True) # initialize indexing\n",
    "image_idx = sample['image']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f1c31e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageTransform():\n",
    "    def __init__(self, mean, std):\n",
    "        self.data_transform = transforms.Compose([\n",
    "            transforms.Resize((256,256)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)\n",
    "        ])\n",
    "    def __call__(self, img):\n",
    "        return self.data_transform(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b4e706b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Img_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, file_list, transform):\n",
    "        self.file_list = file_list\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.file_list[index]\n",
    "        img = Image.open(img_path)\n",
    "        img = img.convert('L')\n",
    "        img_transformed = self.transform(img)\n",
    "        \n",
    "        return img_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1ab2ccbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "# Preparing train dataset, 2021. 5. 19\n",
    "train_img_list = image_idx\n",
    "\n",
    "mean = (0.0,)\n",
    "std = (1.0,)\n",
    "\n",
    "train_dataset = Img_Dataset(file_list = train_img_list,\n",
    "                            transform=ImageTransform(mean, std))\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "batch_iterator = iter(train_dataloader)\n",
    "images = next(batch_iterator)\n",
    "\n",
    "print(images.size())\n",
    "\n",
    "# torch.Size[Batch Size, Channel, Width, Height]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "06788f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare test features 2021. 5. 19\n",
    "test_image_idx = test['image']\n",
    "test_img_list = test_image_idx\n",
    "\n",
    "test_dataset = Img_Dataset(file_list = test_img_list,\n",
    "                            transform=ImageTransform(mean, std))\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "batch_iterator = iter(test_dataloader)\n",
    "test_images = next(batch_iterator)\n",
    "\n",
    "len(batch_iterator)\n",
    "#print(test_images.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b4d20b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/750 [00:00<?, ?it/s]<ipython-input-120-82a027b5f120>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  V = torch.tensor(V)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 750/750 [04:37<00:00,  2.70it/s]\n"
     ]
    }
   ],
   "source": [
    "# Making **train** features, 2021. 5. 19 \n",
    "DEVICE = 'cuda'\n",
    "\n",
    "train_feature = []\n",
    "train_feature = torch.tensor(train_feature)\n",
    "\n",
    "# transfer to DEVICE (GPU memory)\n",
    "train_feature = train_feature.to(DEVICE)\n",
    "\n",
    "a = 1\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        batch = batch.to(DEVICE)\n",
    "        batch = batch.permute(0,2,3,1)[:,:,:,0]\n",
    "        idx, row, col = batch.shape\n",
    "        batch = batch.view([len(batch),-1])\n",
    "\n",
    "        U,S,V = torch.pca_lowrank(batch, q=len(batch), center=True, niter=3)\n",
    "        V = torch.tensor(V)\n",
    "        #print('U shape : ', U.shape)\n",
    "        #print('S shape : ', S.shape)\n",
    "        #print('V shape : ', V.shape)\n",
    "        \n",
    "        train_feature = torch.cat([train_feature, V.T[:,:K]], dim = 0)\n",
    "        #print('train_feature shape: ', train_feature.shape)\n",
    "        \n",
    "        # For debugging (breaking)\n",
    "        #if a == 3:\n",
    "        #    break\n",
    "        #print('iter num : ', a)\n",
    "        a = a + 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "285f9a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving **train** Features 2021. 5. 19\n",
    "train_feature = train_feature.data.cpu().numpy()\n",
    "np.savetxt('trained_feature.csv', train_feature, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "74076b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading **train** Features 2021. 5. 19\n",
    "train_feature = np.loadtxt('trained_feature.csv', delimiter=\",\")\n",
    "train_feature = torch.from_numpy(train_feature)\n",
    "train_feature = train_feature.to(DEVICE)\n",
    "\n",
    "# l2 norm to kill all the sim in 0-1   ** train_feature\n",
    "from sklearn.preprocessing import normalize\n",
    "train_feature = train_feature.data.cpu().numpy()\n",
    "train_feature = np.vstack(train_feature)\n",
    "train_feature = normalize(train_feature)\n",
    "train_feature = torch.from_numpy(train_feature)\n",
    "train_feature = train_feature.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c2d301c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/63 [00:00<?, ?it/s]<ipython-input-170-54f1199d7145>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  V = torch.tensor(V)\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:20<00:00,  3.05it/s]\n"
     ]
    }
   ],
   "source": [
    "# Making **test** features, 2021. 5. 19 \n",
    "DEVICE = 'cuda'\n",
    "\n",
    "test_feature = []\n",
    "test_feature = torch.tensor(test_feature)\n",
    "\n",
    "# transfer to DEVICE (GPU memory)\n",
    "test_feature = test_feature.to(DEVICE)\n",
    "\n",
    "a = 1\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        batch = batch.to(DEVICE)\n",
    "        batch = batch.permute(0,2,3,1)[:,:,:,0]\n",
    "        idx, row, col = batch.shape\n",
    "        batch = batch.view([len(batch),-1])\n",
    "\n",
    "        U,S,V = torch.pca_lowrank(batch, q=len(batch), center=True, niter=3)\n",
    "        V = torch.tensor(V)\n",
    "        #print('U shape : ', U.shape)\n",
    "        #print('S shape : ', S.shape)\n",
    "        #print('V shape : ', V.shape)\n",
    "        \n",
    "        test_feature = torch.cat([test_feature, V.T[:,:K]], dim = 0)\n",
    "        #print('test_feature shape: ', test_feature.shape)\n",
    "        \n",
    "        # For debugging (breaking)\n",
    "        #if a == 3:\n",
    "        #    break\n",
    "        #print('iter num : ', a)\n",
    "        a = a + 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "c726f504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving **test** Features 2021. 5. 19\n",
    "test_feature = test_feature.data.cpu().numpy()\n",
    "np.savetxt('test_feature.csv', test_feature, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "b59bf9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading **test** Features 2021. 5. 19\n",
    "test_feature = np.loadtxt('test_feature.csv', delimiter=\",\")\n",
    "test_feature = torch.from_numpy(test_feature)\n",
    "test_feature = test_feature.to(DEVICE)\n",
    "\n",
    "# l2 norm to kill all the sim in 0-1    ** test_feature\n",
    "test_feature = test_feature.data.cpu().numpy()\n",
    "test_feature = np.vstack(test_feature)\n",
    "test_feature = normalize(test_feature)\n",
    "test_feature = torch.from_numpy(test_feature)\n",
    "test_feature = test_feature.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "8a001f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██                                                                                | 3/120 [00:00<00:05, 21.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding similar images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 120/120 [00:05<00:00, 22.28it/s]\n",
      "<ipython-input-168-676261c3d217>:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sample['predicted_label'] = preds\n"
     ]
    }
   ],
   "source": [
    "# Checking train_feature with train_feature, 2021. 5. 19\n",
    "preds = []\n",
    "CHUNK = 100\n",
    "\n",
    "print('Finding similar images...')\n",
    "CTS = len(train_feature)//CHUNK\n",
    "if len(train_feature)%CHUNK != 0:\n",
    "    CTS += 1\n",
    "    \n",
    "for j in tqdm(range(CTS)):\n",
    "    a = j*CHUNK\n",
    "    b = (j+1)*CHUNK\n",
    "    b = min(b, len(train_feature))\n",
    "    #print('chunk', a, 'to', b)\n",
    "    \n",
    "    #distances = torch.cdist(train_feature, train_feature[a:b], p=2.0).T\n",
    "    distances = torch.matmul(train_feature, train_feature[a:b].T).T\n",
    "    distances = distances.data.cpu().numpy()\n",
    "    \n",
    "    #print(type(distances))\n",
    "    #print(distances.shape)\n",
    "    '''\n",
    "    for k in range(b-a):\n",
    "        IDX = np.argmin(distances[k][:])\n",
    "        o = sample.iloc[IDX].label_group\n",
    "        preds.append(o)\n",
    "    '''\n",
    "    \n",
    "    for k in range(b-a):\n",
    "        #IDX = np.argmax(distances[k][:])\n",
    "        IDX = np.where(distances[k,]>0.95)[0][:]\n",
    "        o = sample.iloc[IDX].label_group.values\n",
    "        preds.append(o)\n",
    "        #print(len(IDX))\n",
    "    \n",
    "sample['predicted_label'] = preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d81f16d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.68246355e-01, -1.16132840e-01,  4.19594653e-01, ...,\n",
       "        -5.86927546e-01, -6.87523003e-02, -1.83017574e-02],\n",
       "       [-3.34991036e-01, -4.53910072e-01,  1.15669825e-01, ...,\n",
       "         4.49153745e-01,  1.70050367e-01,  2.68728962e-02],\n",
       "       [-4.79847594e-01, -2.99720544e-01,  6.53674125e-01, ...,\n",
       "        -7.24444193e-01,  1.47490097e-02, -4.69505347e-04],\n",
       "       ...,\n",
       "       [ 4.60027185e-01,  3.93653413e-01, -5.54306925e-01, ...,\n",
       "         1.00000000e+00, -1.00492205e-02, -2.18378773e-01],\n",
       "       [-2.01583515e-01, -1.55051082e-01,  2.28743321e-01, ...,\n",
       "        -1.00492205e-02,  1.00000000e+00,  1.50841058e-01],\n",
       "       [-4.92016045e-02, -8.76071869e-02,  3.77584134e-02, ...,\n",
       "        -2.18378773e-01,  1.50841058e-01,  1.00000000e+00]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "565c7023",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of correct :  12000\n",
      "precision :  100.0\n",
      "recall :  0.47925798564744226\n",
      "f1 :  0.9539441179310858\n"
     ]
    }
   ],
   "source": [
    "# Scoring\n",
    "# Calculate Precision\n",
    "correct = 0\n",
    "for i in range(len(sample)):\n",
    "    if len( np.intersect1d(sample['predicted_label'][i], sample['label_group'][i])) == 1:\n",
    "        correct = correct + 1\n",
    "\n",
    "precision = correct/len(sample) * 100\n",
    "print('num of correct : ', correct)\n",
    "print('precision : ', precision)\n",
    "\n",
    "# Calculate Recall\n",
    "correct = 0\n",
    "recall = 0\n",
    "temp = 0\n",
    "\n",
    "for i in range(len(sample)):\n",
    "    if len( np.intersect1d(sample['predicted_label'][i], sample['label_group'][i])) == 1:\n",
    "        L = len(sample['predicted_label'][i])\n",
    "        correct = correct + 1\n",
    "        temp = 1/L\n",
    "        recall = recall + temp\n",
    "\n",
    "recall = recall / correct\n",
    "print('recall : ', recall)\n",
    "\n",
    "# Calculate F1 score\n",
    "print('f1 : ', 2*(precision * recall)/(precision + recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "ae68d8c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 2/10 [00:00<00:00, 18.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding similar images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 19.17it/s]\n"
     ]
    }
   ],
   "source": [
    "# Checking train_feature with test_feature, 2021. 5. 19\n",
    "preds = []\n",
    "CHUNK = 100\n",
    "\n",
    "print('Finding similar images...')\n",
    "CTS = len(test_feature)//CHUNK\n",
    "if len(test_feature)%CHUNK != 0:\n",
    "    CTS += 1\n",
    "    \n",
    "for j in tqdm(range(CTS)):\n",
    "    a = j*CHUNK\n",
    "    b = (j+1)*CHUNK\n",
    "    b = min(b, len(test_feature))\n",
    "    #print('chunk', a, 'to', b)\n",
    "    \n",
    "    #distances = torch.cdist(train_feature, test_feature[a:b], p=2.0).T\n",
    "    distances = torch.matmul(train_feature, test_feature[a:b].T).T\n",
    "    distances = distances.data.cpu().numpy()\n",
    "    \n",
    "    #print(type(distances))\n",
    "    #print(distances.shape)\n",
    "    \n",
    "    for k in range(b-a):\n",
    "        #IDX = np.argmax(distances[k][:])\n",
    "        IDX = np.where(distances[k,]>0.9)[0][:]\n",
    "        o = sample.iloc[IDX].label_group.values\n",
    "        preds.append(o)\n",
    "        #print(len(IDX))\n",
    "        \n",
    "test['predicted_label'] = preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "9beca0ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3151"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test['predicted_label'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "fe9cc611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of correct :  95\n",
      "precision :  9.5\n",
      "recall :  0.0005024940435086099\n",
      "f1 :  0.0010049349318785481\n"
     ]
    }
   ],
   "source": [
    "# Scoring\n",
    "# Calculate Precision\n",
    "correct = 0\n",
    "for i in range(len(test)):\n",
    "    if len( np.intersect1d(test['predicted_label'][i], test['label_group'][i])) == 1:\n",
    "        correct = correct + 1\n",
    "\n",
    "precision = correct/len(test) * 100\n",
    "print('num of correct : ', correct)\n",
    "print('precision : ', precision)\n",
    "\n",
    "# Calculate Recall\n",
    "correct = 0\n",
    "recall = 0\n",
    "temp = 0\n",
    "\n",
    "for i in range(len(test)):\n",
    "    if len( np.intersect1d(test['predicted_label'][i], test['label_group'][i])) == 1:\n",
    "        L = len(test['predicted_label'][i])\n",
    "        correct = correct + 1\n",
    "        temp = 1/L\n",
    "        recall = recall + temp\n",
    "\n",
    "recall = recall / correct\n",
    "print('recall : ', recall)\n",
    "\n",
    "# Calculate F1 score\n",
    "print('f1 : ', 2*(precision * recall)/(precision + recall))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
